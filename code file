import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

# df must already exist and have a column named "feedback"

def extract_front_store_terms(df, text_col="feedback",
                              n_clusters=2, top_n=30):
    """
    Cluster feedback into topics and return the terms associated with
    the 'front store' cluster based on your feedback text.
    """
    # 1) Clean / cast to string
    texts = df[text_col].astype(str).values

    # 2) TF-IDF representation
    vectorizer = TfidfVectorizer(
        lowercase=True,
        stop_words="english",
        ngram_range=(1, 2),   # unigrams + bigrams
        min_df=2              # ignore very rare terms
    )
    X = vectorizer.fit_transform(texts)

    # 3) KMeans clustering (e.g., 2 clusters: pharmacy vs front store)
    kmeans = KMeans(
        n_clusters=n_clusters,
        random_state=42,
        n_init=10
    )
    kmeans.fit(X)

    feature_names = np.array(vectorizer.get_feature_names_out())

    # helper: get top terms for a cluster based on centroid weights
    def top_terms_for_cluster(cluster_idx, N=top_n):
        center = kmeans.cluster_centers_[cluster_idx]
        top_ids = np.argsort(center)[::-1][:N]
        return feature_names[top_ids]

    # 4) Get terms for each cluster
    cluster_terms = {
        c: top_terms_for_cluster(c, top_n)
        for c in range(n_clusters)
    }

    # 5) Heuristic: choose which cluster is "front store"
    FRONT_HINTS = {
        "store", "front", "aisle", "checkout", "cashier",
        "sale", "discount", "product", "items", "clean"
    }
    PHARM_HINTS = {
        "pharmacy", "rx", "prescription", "medication",
        "medications", "refill", "pharmacist", "copay"
    }

    def score_cluster(terms, hint_words):
        text = " ".join(terms)
        return sum(h in text for h in hint_words)

    # Try to pick front store cluster:
    #   highest score on FRONT_HINTS and lowest on PHARM_HINTS
    scores = []
    for c, terms in cluster_terms.items():
        fs_score = score_cluster(terms, FRONT_HINTS)
        ph_score = score_cluster(terms, PHARM_HINTS)
        scores.append((c, fs_score, ph_score))

    # Prefer clusters with high front score and low pharmacy score
    front_cluster = max(
        scores,
        key=lambda x: (x[1], -x[2])   # maximize fs_score, minimize ph_score
    )[0]

    front_store_terms = cluster_terms[front_cluster]
    return front_store_terms, cluster_terms, kmeans, vectorizer


# ===============================
# Example usage
# ===============================

# front_store_terms will be a list/array of the top words & bigrams
# that your data suggests are related to front store.
front_store_terms, all_cluster_terms, km, vec = extract_front_store_terms(df)

print("=== Front store related terms ===")
for t in front_store_terms:
    print(t)

print("\n=== Other cluster terms (likely pharmacy) ===")
for c, terms in all_cluster_terms.items():
    print(f"\nCluster {c}:")
    print(", ".join(terms))


WITH table_list AS (
    SELECT 'TABLE_1' AS table_name UNION ALL
    SELECT 'TABLE_2' UNION ALL
    SELECT 'TABLE_3' UNION ALL
    SELECT 'TABLE_4'
),
counts AS (
    SELECT 
        table_name,
        (SELECT COUNT(*) FROM IDENTIFIER(table_name)) AS row_count
    FROM table_list
)
SELECT * FROM counts;
